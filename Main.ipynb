{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fa70122",
   "metadata": {},
   "source": [
    "# Combination of datasets prior to further modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbc3b32",
   "metadata": {},
   "source": [
    "### The purpose of this notebook is combine datasets pulled from different areas of the data warehouse. The initial dataset will be all those currenthly present in the dim person table. Further to this, datasets regarding such areas as disease status, alcohol consumption and social satus will be joined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da34d3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All packaged required are loaded here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b31a882",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.txt', sep='\\t', header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874f2416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we asssess those who have become deceased in our dataset.\n",
    "# We create a deceased date from the two existing columns\n",
    "# We take those who have died in the last 12 months using a cut off\n",
    "# We then remove those who have died but not in the last 12 months\n",
    "df_deceased = df[df.IsDeceased == 1]\n",
    "df_deceased['DeceasedYear'] = df_deceased['DeceasedYear'].astype(int)\n",
    "df_deceased['DeceasedMonth'] = df_deceased['DeceasedMonth'].astype(int)\n",
    "df_deceased['DeceasedDate'] = df_deceased['DeceasedYear'].astype(str) + '-' + df_deceased['DeceasedMonth'].astype(str)\n",
    "df_deceased['DeceasedDate'] = df_deceased['DeceasedDate'].astype(str) + '-01'\n",
    "df_deceased[[\"DeceasedDate\"]] = df_deceased[[\"DeceasedDate\"]].apply(pd.to_datetime)\n",
    "df_deceased['Cutoff'] = '2024-07-12'\n",
    "df_deceased[['Cutoff']] = df_deceased[['Cutoff']].apply(pd.to_datetime)\n",
    "df_deceased['DeathDifference'] = (df_deceased['Cutoff'] - df_deceased['DeceasedDate']).dt.days\n",
    "df_deceased['Target'] = df_deceased.apply(lambda row: 1 if row['DeathDifference'] <= 365 else 0, axis=1)\n",
    "df_deceased = df_deceased[df_deceased.Target == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472ee142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we seperate those who are alive\n",
    "# We then create the same columns in the deceased dataset \n",
    "df_alive = df[df.IsDeceased == 0]\n",
    "df_alive['DeceasedMonth'] = df_alive['DeceasedMonth'].fillna(1.0).astype(int)\n",
    "df_alive['DeceasedYear'] = df_alive['DeceasedYear'].fillna(1900).astype(int)\n",
    "df_alive['DeceasedDate'] = df_alive['DeceasedYear'].astype(str) + '-' + df_alive['DeceasedMonth'].astype(str)\n",
    "df_alive['DeceasedDate'] = df_alive['DeceasedDate'].astype(str) + '-01'\n",
    "df_alive[[\"DeceasedDate\"]] = df_alive[[\"DeceasedDate\"]].apply(pd.to_datetime)\n",
    "df_alive['Cutoff'] = '2024-07-12'\n",
    "df_alive[['Cutoff']] = df_alive[['Cutoff']].apply(pd.to_datetime)\n",
    "df_alive['DeathDifference'] = (df_alive['Cutoff'] - df_deceased['DeceasedDate']).dt.days\n",
    "df_alive['Target'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef1655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we join the deceased and alive dataset\n",
    "# We then shuffle the dataset to introduce some randomness\n",
    "df = df_deceased._append(df_alive)\n",
    "df = shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da8be8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We remove any columns regarded as unecessary in order to streamline the dataset.\n",
    "df = df.drop(['Pseudonym','CurrentGpSurgeryKey','CurrentGpSurgeryRegistrationDateKey','Gender','OutputArea',\n",
    "             'LowerSuperOutputArea','MiddleSuperOutputArea','MiddleSuperOutputAreaName','Latitude','Longitude',\n",
    "             'WardCode','WardName','LocalAuthorityCode','FiveYearAgeBand','FiveYearAgeBandOrder',\n",
    "             'TenYearAgeBandOrder','SegmentAgeBand','SegmentAgeBandOrder','EthnicityReadCode',\n",
    "             'EthnicityCodeDescription','EthnicityGroupDescription','EthnicityRecordedDateKey',\n",
    "             'Cutoff','LocalAuthorityName','SpeaksEnglish','IsDeceased','DeceasedYear','DeathDifference','TenYearAgeBand',\n",
    "             'EthnicityGroupDetailDescription','GenderShort'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4a224d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PersonKey</th>\n",
       "      <th>Age</th>\n",
       "      <th>BirthMonth</th>\n",
       "      <th>IsLsoaCoastal</th>\n",
       "      <th>ImdDecile</th>\n",
       "      <th>LowerSuperOutputAreaDeprivationDecile</th>\n",
       "      <th>LowerSuperOutputAreaIncomeDecile</th>\n",
       "      <th>LowerSuperOutputAreaEmploymentDecile</th>\n",
       "      <th>LowerSuperOutputAreaEducationSkillsAndTrainingDecile</th>\n",
       "      <th>LowerSuperOutputAreaHealthDeprivationAndDisabilityDecile</th>\n",
       "      <th>...</th>\n",
       "      <th>MosaicKeyFeature2</th>\n",
       "      <th>MosaicKeyFeature3</th>\n",
       "      <th>MosaicKeyFeature4</th>\n",
       "      <th>MosaicKeyFeature5</th>\n",
       "      <th>MosaicKeyFeature6</th>\n",
       "      <th>DeceasedMonth</th>\n",
       "      <th>IsOptedOut</th>\n",
       "      <th>IsNewDorsetRegistration</th>\n",
       "      <th>DeceasedDate</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>852360</th>\n",
       "      <td>288892</td>\n",
       "      <td>16</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13414.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Families with children</td>\n",
       "      <td>Oil/solid fuel central heating</td>\n",
       "      <td>Internet via smartphone</td>\n",
       "      <td>Single trip travel insurance</td>\n",
       "      <td>Free mobile phone apps</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270639</th>\n",
       "      <td>776054</td>\n",
       "      <td>48</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>31005.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No children</td>\n",
       "      <td>Rented 1 bed flats</td>\n",
       "      <td>Work full-time</td>\n",
       "      <td>Text messages</td>\n",
       "      <td>Electric central heating</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77598</th>\n",
       "      <td>1357606</td>\n",
       "      <td>17</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16056.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Older households, no children</td>\n",
       "      <td>Homeowners</td>\n",
       "      <td>Garden or allotment</td>\n",
       "      <td>Internet from desktop/laptop</td>\n",
       "      <td>Free mobile phone apps</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873012</th>\n",
       "      <td>296125</td>\n",
       "      <td>29</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13189.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No children</td>\n",
       "      <td>Rented 1 bed flats</td>\n",
       "      <td>Work full-time</td>\n",
       "      <td>Text messages</td>\n",
       "      <td>Electric central heating</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379498</th>\n",
       "      <td>814124</td>\n",
       "      <td>16</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7415.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>School-age children</td>\n",
       "      <td>No qualifications</td>\n",
       "      <td>Low discretionary income</td>\n",
       "      <td>Standard current/savings account</td>\n",
       "      <td>Single trip travel insurance</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PersonKey  Age  BirthMonth  IsLsoaCoastal  ImdDecile  \\\n",
       "852360     288892   16         3.0              1        5.0   \n",
       "270639     776054   48         8.0              0       10.0   \n",
       "77598     1357606   17         7.0              0        5.0   \n",
       "873012     296125   29         7.0              0        5.0   \n",
       "379498     814124   16         5.0              1        3.0   \n",
       "\n",
       "        LowerSuperOutputAreaDeprivationDecile  \\\n",
       "852360                                13414.0   \n",
       "270639                                31005.0   \n",
       "77598                                 16056.0   \n",
       "873012                                13189.0   \n",
       "379498                                 7415.0   \n",
       "\n",
       "        LowerSuperOutputAreaIncomeDecile  \\\n",
       "852360                               5.0   \n",
       "270639                              10.0   \n",
       "77598                                6.0   \n",
       "873012                               4.0   \n",
       "379498                               2.0   \n",
       "\n",
       "        LowerSuperOutputAreaEmploymentDecile  \\\n",
       "852360                                   4.0   \n",
       "270639                                   9.0   \n",
       "77598                                    5.0   \n",
       "873012                                   4.0   \n",
       "379498                                   3.0   \n",
       "\n",
       "        LowerSuperOutputAreaEducationSkillsAndTrainingDecile  \\\n",
       "852360                                                3.0      \n",
       "270639                                                9.0      \n",
       "77598                                                 2.0      \n",
       "873012                                                3.0      \n",
       "379498                                                2.0      \n",
       "\n",
       "        LowerSuperOutputAreaHealthDeprivationAndDisabilityDecile  ...  \\\n",
       "852360                                                3.0         ...   \n",
       "270639                                                9.0         ...   \n",
       "77598                                                 7.0         ...   \n",
       "873012                                                5.0         ...   \n",
       "379498                                                3.0         ...   \n",
       "\n",
       "                    MosaicKeyFeature2               MosaicKeyFeature3  \\\n",
       "852360         Families with children  Oil/solid fuel central heating   \n",
       "270639                    No children              Rented 1 bed flats   \n",
       "77598   Older households, no children                      Homeowners   \n",
       "873012                    No children              Rented 1 bed flats   \n",
       "379498            School-age children               No qualifications   \n",
       "\n",
       "               MosaicKeyFeature4                 MosaicKeyFeature5  \\\n",
       "852360   Internet via smartphone      Single trip travel insurance   \n",
       "270639            Work full-time                     Text messages   \n",
       "77598        Garden or allotment      Internet from desktop/laptop   \n",
       "873012            Work full-time                     Text messages   \n",
       "379498  Low discretionary income  Standard current/savings account   \n",
       "\n",
       "                   MosaicKeyFeature6  DeceasedMonth  IsOptedOut  \\\n",
       "852360        Free mobile phone apps              1           0   \n",
       "270639      Electric central heating              1           0   \n",
       "77598         Free mobile phone apps              1           0   \n",
       "873012      Electric central heating              1           0   \n",
       "379498  Single trip travel insurance              1           0   \n",
       "\n",
       "        IsNewDorsetRegistration  DeceasedDate  Target  \n",
       "852360                        0    1900-01-01       0  \n",
       "270639                        0    1900-01-01       0  \n",
       "77598                         0    1900-01-01       0  \n",
       "873012                        0    1900-01-01       0  \n",
       "379498                        0    1900-01-01       0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We remove any rows which have NAs for future compuational reasons\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b99354c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Target\n",
       "0    801013\n",
       "1      8710\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we can now see how many people we habe who died within the last 12 months\n",
    "df.Target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae579a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the mosaic features are categorical examples. These will need to be turned into numeric features for modelling.\n",
    "# A for loop is used to identify those columns which are mosaic and turn them intp numbers\n",
    "for col in df.columns:\n",
    "    if 'Mosaic' in col:\n",
    "        df[col] = pd.factorize(df[col])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1fd710",
   "metadata": {},
   "source": [
    "## The joining of disease condition status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08179cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here we import data for various diseases\n",
    "disease = pd.read_csv('disease.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaf6fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This piece of code determines whether or not a disease was diagnosed within the last 5 years.\n",
    "# We pick a reference date to calculate the 5 year period\n",
    "reference_date = datetime(2024, 7, 12)\n",
    "\n",
    "# This is a function which determines if a date is wiithin 5 years of our reference\n",
    "def within_5_years(date, reference):\n",
    "    return int(abs((date - reference).days) <= 5 * 365)\n",
    "\n",
    "# Loop through columns with 'date' in their names and process them\n",
    "for col in disease.columns:\n",
    "    if 'Date' in col:\n",
    "        try:\n",
    "            # Attempt to convert the column to datetime\n",
    "            disease[col] = pd.to_datetime(disease[col], errors='coerce')\n",
    "            \n",
    "            # If conversion is successful, create the new binary column\n",
    "            new_col_name = col[0:5] + '_within_5_years'\n",
    "            disease[new_col_name] = disease[col].apply(lambda x: within_5_years(x, reference_date) if pd.notnull(x) else 0)\n",
    "        except Exception as e:\n",
    "            # Handle any unexpected exceptions\n",
    "            print(f\"An error occurred while processing column {col}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce02e004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We join the diseases data onto our intial data based on the personkey\n",
    "df = df.merge(disease, on='PersonKey', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada79726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Target\n",
       "0    801013\n",
       "1      8710\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We replace any missing data with 0s as we can assume a person does not have the disease if not in the table\n",
    "df = df.replace(np.nan, 0)\n",
    "df.Target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d794b2b0",
   "metadata": {},
   "source": [
    "## We now join data concerning patients visits to the GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20df11f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read in the data and add the required the column names.\n",
    "# We also add a one to each entry, this is so we can sum the number of appointments later.\n",
    "# We then group by the number of appointments for each person and reset the index\n",
    "Primary = pd.read_csv('Primary.txt', sep='\\t', header = 0)\n",
    "prim_cols = ['PersonKey','AppointmentDateKey','DidNotAttend']\n",
    "Primary.columns = prim_cols\n",
    "Primary['Appointment'] = 1\n",
    "app_group = Primary.groupby('PersonKey')['Appointment'].sum()\n",
    "primary_app = app_group.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13d1b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61824"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We again merge the new GP data onto the evolving data frame\n",
    "df = df.merge(primary_app, on='PersonKey', how='left')\n",
    "df.Appointment.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf219010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now convert the appointdate of each persons appointments to datetime and extract there years\n",
    "Primary['AppointmentDateKey'] = pd.to_datetime(Primary['AppointmentDateKey'])\n",
    "Primary['Year'] = Primary.AppointmentDateKey.dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bb223d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now createb a pivot table, which sums the number of apps a person has per year\n",
    "# We then reset the index and take only those columns for 2023 and 2024\n",
    "# We reset the column names and join this data to our dataframe\n",
    "pivoted = Primary.pivot_table(index='PersonKey', columns='Year', values='Appointment',aggfunc='sum')\n",
    "pivoted = pivoted.reset_index()\n",
    "pivoted = pivoted[['PersonKey',2023,2024]]\n",
    "pivoted = pivoted.reset_index(drop=True)\n",
    "cols = ['PersonKey','2023_appointments','2024_appointments']\n",
    "pivoted.columns = cols\n",
    "df = df.merge(pivoted, on = 'PersonKey', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303ca00c",
   "metadata": {},
   "source": [
    "## Here we join any data concerning a persons trips to A&E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63b9998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we read in our emergency data and apply the relevant column names.\n",
    "# We now again apply a count and groupby a persons number of visits.\n",
    "# We then reset our index and finally merge the datasets\n",
    "Emergency = pd.read_csv('Emergency.txt', sep='\\t', header = None)\n",
    "Emergency.columns = [\"PersonKey\", \"AppointmentDateKey\", \"DidNotAttend\"]\n",
    "Emergency['Visit'] = 1\n",
    "em_group = Emergency.groupby('PersonKey')['Visit'].sum()\n",
    "emergency_app = em_group.reset_index()\n",
    "df = df.merge(emergency_app, on='PersonKey', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bb1da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The date of each A&E visit is then converted to a datetime and the years extracted.\n",
    "# Again a pivot table sums the number of visits for each person.\n",
    "# We then select only 2023,2024 visits, apply new column names and merge onto our dataset.\n",
    "# We can replace NAs with 0s again the person had no visits if not in the dataset.\n",
    "Emergency['AppointmentDateKey'] = pd.to_datetime(Emergency['AppointmentDateKey'])\n",
    "Emergency['Year'] = Emergency.AppointmentDateKey.dt.year\n",
    "pivoted = Emergency.pivot_table(index='PersonKey', columns='Year', values='Visit',aggfunc='sum')\n",
    "pivoted = pivoted.reset_index()\n",
    "pivoted = pivoted[['PersonKey',2023,2024]]\n",
    "pivoted = pivoted.reset_index(drop=True)\n",
    "cols = ['PersonKey','2023_visitsA_E','2024_visitsA_E']\n",
    "pivoted.columns = cols\n",
    "df = df.merge(pivoted, on='PersonKey', how='left')\n",
    "df = df.replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8fa5b9",
   "metadata": {},
   "source": [
    "## We now add in further data regarding a person's alcohol consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c10fa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The alcohol data is read in and the appropiate columns given\n",
    "# The data is then merged onto our dataset and nas are dealt with\n",
    "alcohol = pd.read_csv('Alcohol.txt', sep='\\t', header = None)\n",
    "alc_cols = ['PersonKey','AlcoholConsumptionUnitsPerWeek','AlcoholConsumptionUnitsPerWeekDateKey']\n",
    "alcohol.columns = alc_cols\n",
    "df = df.merge(alcohol, on='PersonKey', how='left')\n",
    "df = df.replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957d602c",
   "metadata": {},
   "source": [
    "## Further clinical data about each patient is then appended here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd74f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data is read in and columns added.\n",
    "# We then append the new data and fill in any missing values\n",
    "Clinical = pd.read_csv('clinical.txt', sep='\\t', header = None)\n",
    "clinical_cols = ['PersonKey','BmiValue','BmiCheckDateKey','IsObese','ObeseCheckDateKey','CholesterolValue',\n",
    "                 'CholesterolCheckDateKey','FluVaccinationRecorded','FluVaccinationDatekey','SeizuresPerYear',\n",
    "                 'SeizuresPerYearCheckDateKey','ReducedMobility','ReducedMobilityDateKey','ConfinedToChair',\n",
    "                 'ConfinedToChairDateKey','BedRidden','BedRiddenDateKey','HeartRateValue','HeartRateValueCheckDateKey',\n",
    "                'SystolicBpValue','DiastolicBpValue','MalnutritionUniversalScreeningTool','MalnutritionUniversalScreeningToolScoreValue']\n",
    "Clinical.columns = clinical_cols\n",
    "df = df.merge(Clinical, on='PersonKey', how='left')\n",
    "df = df.replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe22b9e",
   "metadata": {},
   "source": [
    "## Here we attach any data referring to mental health services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6b7e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read in the datat for mental health referrals\n",
    "M_health = pd.read_csv('Mental.csv')\n",
    "M_health['M_visit'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f9b424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We name and apply the relevant column names\n",
    "# We then add a numeric value called visit so we can sum later\n",
    "# We group by the person key and number of referrals\n",
    "# We reset the index and then merge on the personkey column\n",
    "M_het = M_health[['PersonKey','ReferralID','M_visit']]\n",
    "M_group = M_het.groupby('PersonKey')['M_visit'].sum()\n",
    "M_app = M_group.reset_index()\n",
    "df = df.merge(M_app, on='PersonKey', how='left')\n",
    "df = df.replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4d7bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we create a pivot table for the reasons for mental health referral\n",
    "# We select only a few reasons to be appended to the dataset\n",
    "pivoted = M_health.pivot_table(index='PersonKey', columns='ReferralReason', values='M_visit',aggfunc='sum')\n",
    "pivoted = pivoted.reset_index()\n",
    "pivoted = pivoted[['PersonKey','Anxiety','Depression','Self harm behaviours','Eating disorders','Bi polar disorder',\n",
    "                   'Drug and alcohol difficulties','Ongoing or Recurrent Psychosis']]\n",
    "pivoted = pivoted.reset_index(drop=True)\n",
    "df = df.merge(pivoted, on='PersonKey', how='left')\n",
    "df = df.replace(np.nan, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a4729d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rowt\\AppData\\Local\\Temp\\ipykernel_22944\\396056291.py:1: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  M_health['ReferralDate'] = pd.to_datetime(M_health['ReferralDate'])\n"
     ]
    }
   ],
   "source": [
    "# Here we group on the number of referrals per person\n",
    "# We then total those for 2023 and 2024 and append them to a dataframe.\n",
    "M_health['ReferralDate'] = pd.to_datetime(M_health['ReferralDate'])\n",
    "M_health['Year'] = M_health.ReferralDate.dt.year\n",
    "pivoted = M_health.pivot_table(index='PersonKey', columns='Year', values='M_visit',aggfunc='sum')\n",
    "pivoted = pivoted.reset_index()\n",
    "pivoted = pivoted[['PersonKey',2023,2024]]\n",
    "pivoted = pivoted.reset_index(drop=True)\n",
    "cols = ['PersonKey','2023_visits_M','2024_visits_M']\n",
    "pivoted.columns = cols\n",
    "df = df.merge(pivoted, on='PersonKey', how='left')\n",
    "df = df.replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b7f536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read in the data for the number of mental health appointments the person has\n",
    "M_contact = pd.read_csv('mental_contact.txt', sep='\\t', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902ee46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create our columns and apply them\n",
    "# We apply a numeric column for later summation\n",
    "# We group by the personkey and number of appointments\n",
    "# Finally we merge on the personkey and replace nans.\n",
    "Meds_contact_cols = ['PersonKey','CareContactDateKey']\n",
    "M_contact.columns = Meds_contact_cols\n",
    "M_contact['MH_app'] = 1\n",
    "M_apps = M_contact.groupby('PersonKey')['MH_app'].sum()\n",
    "M_apps = M_apps.reset_index()\n",
    "df = df.merge(M_apps, on='PersonKey', how='left')\n",
    "df = df.replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfe176b",
   "metadata": {},
   "source": [
    "## Here we append data based on waiting lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5ea761",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rowt\\AppData\\Local\\Temp\\ipykernel_22944\\291117941.py:2: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  Waiting = pd.read_csv('Waiting.txt', sep='\\t', header = None)\n"
     ]
    }
   ],
   "source": [
    "# We read in the data for the number of waiting lists a person is on\n",
    "Waiting = pd.read_csv('Waiting.txt', sep='\\t', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b9498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create our columns and apply them\n",
    "# We apply a numeric column for later summation\n",
    "# We group by the personkey and number of waiting lists\n",
    "# Finally we merge on the personkey and replace nans.\n",
    "Waiting_cols = ['PersonKey','Date','Waiting_time']\n",
    "Waiting.columns = Waiting_cols\n",
    "Waiting['Lists'] = 1\n",
    "Waiting = Waiting[['PersonKey','Lists']]\n",
    "waiting_l = Waiting.groupby('PersonKey')['Lists'].sum()\n",
    "Waiting_l = waiting_l.reset_index()\n",
    "df = df.merge(waiting_l, on='PersonKey', how='left')\n",
    "df = df.replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc86246",
   "metadata": {},
   "source": [
    "## Here we add some additional information regarding social status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a80a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read in the data for the number of waiting lists a person is on\n",
    "Social = pd.read_csv('social.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e525292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We merge on the personkey and replace nans.\n",
    "df = df.merge(Social, on='PersonKey', how='left')\n",
    "df = df.replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46c17e9",
   "metadata": {},
   "source": [
    "## Here we add some data regarding fractures and falls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5110ae43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read in the data for the number of falls and fractures a person has\n",
    "fractures =  pd.read_csv('fractures.txt', sep='\\t', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f275e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create our columns and apply them\n",
    "# We group by the personkey and number falls etc\n",
    "# Finally we merge on the personkey and replace nans.\n",
    "frac_cols = ['PersonKey','RespAdmission','Fractures','Falls']\n",
    "fractures.columns = frac_cols\n",
    "total_fracs = fractures.groupby('PersonKey')[['RespAdmission','Fractures','Falls']].sum()\n",
    "total_fracs = total_fracs.reset_index()\n",
    "df = df.merge(total_fracs, on='PersonKey', how='left')\n",
    "df = df.replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202379c9",
   "metadata": {},
   "source": [
    "## Here we add information regarding a person's smoking status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1304426e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read in smoking data for our population\n",
    "Smoking = pd.read_csv('Smoking.txt', sep='\\t', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0152bf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We apply our column names\n",
    "# We then use a function to assign a binary smoking status based on values\n",
    "# These are smoker and non-smoker. \n",
    "# The smokingstatus variable was then dropped\n",
    "Smoking_cols = ['PersonKey','SmokingStatus']\n",
    "Smoking.columns = Smoking_cols\n",
    "def set_value(row_number, assigned_value):\n",
    "    return assigned_value[row_number]\n",
    "event_dictionary = {'Smoker': 1, 'Ex-Smoker': 1, 'Never Smoked':0,'UNKNOWN':0}\n",
    "# Add a new column named 'Price'\n",
    "Smoking['Smoked'] = Smoking['SmokingStatus'].apply(set_value, args=(event_dictionary, ))\n",
    "Smoking = Smoking.drop(['SmokingStatus'],axis = 1)\n",
    "df = df.merge(Smoking, on='PersonKey', how='left')\n",
    "df = df.replace(np.nan, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc44d39f",
   "metadata": {},
   "source": [
    "## We now add information regarding disabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32402da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read in data regarding disabilities\n",
    "# We then assign a value of 1 for each condition\n",
    "# We groupby the number of conditions per person\n",
    "# We then append the data to our dataframe\n",
    "disable = pd.read_csv('Disability.csv')\n",
    "disable['D_condition'] = 1\n",
    "total_disability = disable.groupby('PersonKey')[['D_condition']].sum()\n",
    "total_disability = total_disability.reset_index()\n",
    "df = df.merge(total_disability, on='PersonKey', how='left')\n",
    "df = df.replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987b55f6",
   "metadata": {},
   "source": [
    "## Here we add some further information regarding Adults social services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d04914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read in data regarding adult social services\n",
    "# We remove duplicates on the personkey\n",
    "# We turn the categorical data into numerical and add 1 in order to fill nans later\n",
    "Adult = pd.read_csv('Adult.csv')\n",
    "Adult = Adult.drop_duplicates(subset=['PersonKey'],keep = 'first')\n",
    "Adult['PrimarySupportReason'] = pd.factorize(Adult['PrimarySupportReason'])[0]\n",
    "Adult['PrimarySupportReason'] = Adult['PrimarySupportReason'] + 1\n",
    "df = df.merge(Adult, on='PersonKey', how='left')\n",
    "df = df.replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8231afad",
   "metadata": {},
   "source": [
    "## Now we can bring in data regarding 111 calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47eb88cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read in data regarding 111 calls\n",
    "# We apply column names and drop duplicates on the caseid\n",
    "# We then groupby on the number of calls and append to our data\n",
    "One_emergency = pd.read_csv('one_urgent.txt', sep='\\t', header = None)\n",
    "One_emergency_cols = ['PersonKey','Caseid','CaseStartDateTime']\n",
    "One_emergency.columns = One_emergency_cols\n",
    "One_emergency = One_emergency.drop_duplicates(subset=['Caseid'], keep='first')\n",
    "One_emergency['Incidents'] = 1\n",
    "One_emergency = One_emergency.groupby('PersonKey')[['Incidents']].sum()\n",
    "One_emergency = One_emergency.reset_index()\n",
    "df = df.merge(One_emergency, on='PersonKey', how='left')\n",
    "df = df.replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b058f4",
   "metadata": {},
   "source": [
    "## We can now add some information regarding Ambulance activity per person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda0b384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read in data regarding ambulance usage\n",
    "# We add our column names and drop duplicates on incidentnumber\n",
    "Ambulance = pd.read_csv('Ambulance.txt', sep='\\t', header = None)\n",
    "Ambulance_cols = ['PersonKey','IncidentNumber','IncidentDateKey']\n",
    "Ambulance.columns = Ambulance_cols\n",
    "Ambulance = Ambulance.drop_duplicates(subset=['IncidentNumber'], keep='first')\n",
    "Ambulance['Call'] = 1\n",
    "Ambulance = Ambulance.groupby('PersonKey')[['Call']].sum()\n",
    "Ambulance = Ambulance.reset_index()\n",
    "df = df.merge(Ambulance, on='PersonKey', how='left')\n",
    "df = df.replace(np.nan, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fe9b14",
   "metadata": {},
   "source": [
    "## Here we read in data regarding covid-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d201d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "Covid_vac = pd.read_csv('Covid_vac.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe24259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we append the covid vulnerability status of each person\n",
    "Covid_risk = Covid_vac.iloc[:,0:4]\n",
    "df = df.merge(Covid_risk, on='PersonKey', how='left')\n",
    "df = df.replace(np.nan, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7609f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we append the number of covid vaccines each person has had\n",
    "# We sum the number of vaccines into a total column\n",
    "column_names = ['CovidVaccinationPart1','CovidVaccinationPart2', 'CovidVaccinationBooster']\n",
    "Covid_vac['Total_Covid_Vaccines']= Covid_vac[column_names].sum(axis=1)\n",
    "Total_vac = Covid_vac[['PersonKey','Total_Covid_Vaccines']]\n",
    "df = df.merge(Total_vac, on='PersonKey', how='left')\n",
    "df = df.replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7b2195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now add whether a person declined their vaccine or had a poor reaction\n",
    "Covid_declined = Covid_vac[['PersonKey','CovidVaccineDeclined','CovidVaccineAdverseReaction']]\n",
    "df = df.merge(Covid_declined, on='PersonKey', how='left')\n",
    "df = df.replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11aac446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we drop any columns with dates in them\n",
    "def drop(df):\n",
    "    for col in df.columns:\n",
    "        if 'Date' in col:\n",
    "            df = df.drop([col], axis =1)\n",
    "        else:\n",
    "            print('no drop')\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aded4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n",
      "no drop\n"
     ]
    }
   ],
   "source": [
    "df = drop(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22557278",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('dataframe.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
